import pandas as pd
import numpy as np
import sklearn
from imblearn.under_sampling import RandomUnderSampler
from sklearn import ensemble
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, classification_report, accuracy_score
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn import preprocessing

store_path = "E:/Emnets/5G/powerMonitor/ZTE/data/final_features_more_feature.csv"
features_final_path = 'E:\\Emnets\\5G\\powerMonitor\\ZTE\data\\'
df_features = pd.read_csv(store_path)
data_feature = df_features.loc[:,:].values
col = np.shape(data_feature)[1]

data_features = data_feature[:,1:col-1]
labels = data_feature[:,col-1]
col = np.shape(data_feature)[1]
print(data_features)
print(np.shape(data_features))
print(labels)
print(np.shape(labels))


le = preprocessing.LabelEncoder()
print(data_features[:,-5])
tran = le.fit_transform(data_features[:,-5])
data_features[:,-5] = tran
print(data_features[:,-5])
# input()

ss = sklearn.preprocessing.MinMaxScaler()
data_features = ss.fit_transform(data_features)
print(np.shape(data_features))
# input()

model_RandomUnderSample = RandomUnderSampler(random_state=73)          # 建立RandomUnderSampler模型对象
x_RandomUnderSampler_resampled, y_RandomUnderSampler_resampled = model_RandomUnderSample.fit_sample(data_features, labels)   # 输入数据做欠抽样处理
x_RandomUnderSampler_resampled = pd.DataFrame(x_RandomUnderSampler_resampled)
y_RandomUnderSampler_resampled =pd.DataFrame(y_RandomUnderSampler_resampled,columns=['50'])
RandomUnderSampler_resampled =pd.concat([x_RandomUnderSampler_resampled, y_RandomUnderSampler_resampled], axis= 1)  # 按列合并数据框
# if not os.path.exists(features_final_path+'final_features_balanced.csv'):
RandomUnderSampler_resampled.to_csv(features_final_path+'final_features_more_feature_balanced.csv')
print(np.array(x_RandomUnderSampler_resampled))
print(np.array(y_RandomUnderSampler_resampled))
x_RandomUnderSampler_resampled = np.squeeze(np.array(x_RandomUnderSampler_resampled))
y_RandomUnderSampler_resampled = np.squeeze(np.array(y_RandomUnderSampler_resampled))
# input()

X_train, X_test, y_train, y_test = train_test_split(x_RandomUnderSampler_resampled, y_RandomUnderSampler_resampled, test_size=0.3, random_state=33)
# X_train, X_test, y_train, y_test = train_test_split(data_features, labels, test_size=0.3, random_state=33)

# # "min_samples_leaf":range(1,10,1),'max_depth':range(1,20,1), 'min_samples_split':range(2,10,1), 'max_features':range(1,46,1)
# # param_grid = {"n_estimators":range(10,201,10)}
# param_grid = {"min_samples_leaf":range(1,10,1),'max_depth':range(1,20,2), 'min_samples_split':range(2,10,1), 'max_features':range(1,51,2)}
#
# # clf = RandomForestClassifier(class_weight='balanced')
# clf = RandomForestClassifier(n_estimators=150,class_weight='balanced')
#
# grid_search=GridSearchCV(clf,param_grid,scoring='roc_auc',n_jobs=-1,verbose=1,cv=5)
# grid_search.fit(X_train,y_train)
# # print(grid_search.best_params_)
# rf_best_model = grid_search.best_estimator_
#
# means = grid_search.cv_results_['mean_test_score']
# std = grid_search.cv_results_['std_test_score']
# params = grid_search.cv_results_['params']
# for mean,std,param in zip(means,std,params):
#     print("mean : %f std : %f %r" % (mean,std,param))
# print('best_estimator :',grid_search.best_estimator_)
# print('best_params :',grid_search.best_params_)
# # best_estimator : RandomForestClassifier(class_weight='balanced', max_depth=13, max_features=10,
# #                       min_samples_split=7, n_estimators=140)

# final random forest model
# final_RF_model = RandomForestClassifier(n_estimators= 60, max_depth=11, min_samples_leaf=3,min_samples_split=9,max_features=41
#                                         ,oob_score=True, random_state=33)
final_RF_model = RandomForestClassifier(n_estimators= 150, max_depth=11, min_samples_leaf=6,min_samples_split=4,max_features=15
                                        ,oob_score=True, random_state=33,class_weight='balanced')
final_RF_model.fit(X_train,y_train)
y_predprob4 = final_RF_model.predict_proba(X_test)[:,1]
print('oob_score : %f ,auc : %f' % (final_RF_model.oob_score_,roc_auc_score(y_test, y_predprob4)))

y_pred = final_RF_model.predict(X_test)
acc = accuracy_score(y_test,y_pred)
print("Accuracy:",acc)
print(classification_report(y_test, y_pred))

print(pd.crosstab(y_test, y_pred, rownames=['actual'], colnames=['preds']))